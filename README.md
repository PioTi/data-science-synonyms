Because many data analysis methods developed relatively independently in statistics, machine learning, biology, physics, chemistry, economics, psychology, engineering fields, and more, there is a lot of overlapping terminology.

This is an an attempt to sort it out.

I don't know the best way to structure this, for now I'm just going to jot some notes here.

* False Positive (ML) = Type 1 Error (Statistics)
* False Negative (ML) = Type 2 Error (Statistics)
* Recall (Information Science) = Sensitivity (Medicine/Biology) = True Positive Rate (ML)
* Precision (Information Science) = Positive Predictive Value (ML)
* True Negative Rate (ML) = Specificity (Medicine/Biology)
* Gaussian Distribution (Physics) = Normal Distribution (Statistics) = Bell Curve (Colloquial)
* Hypothesis (Statistics) = Model (ML)
* Marginal Likelihood (Frequentist) = Evidence (Bayesian)

Lots of good ones for stochastics optimization problems!

* Rough Landscape (Stochastic Optimization) = NP Complete (Computer Science)
* Cost Function (Economics) = Loss Function (Statistics) = Utility (Economics) = Objective Function (Operations Management) = Reward Function () = Energy (Physics/Chemistry) = Fitness (Evolutionary Biology)
* Search Space

These are not *exactly* equivalent, but are extremely closely related. **NOTE: How could we illustrate that?**

* Structural Equation Model (Statistics) = Latent Variable Model () = Hidden Variable Model (Physics) = Bayesian Network (ML)

